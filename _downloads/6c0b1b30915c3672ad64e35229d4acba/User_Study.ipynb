{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# User Study\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport harmonicsonification as hs\nhs.seed_everything(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Set Creation\n\nWe want to test whether our harmonic sonification approach allows users to distinguish typical data points from\noutliers just based on the sound. For this, we first create an artificial data set with the characteristics\ntypically obtained from applying PCA (i.e. dimensions with decreasing variance). We then create an _outlier_ data\nset with uniformly distributed points (some of these points will be like typical data points, but most will fall\noutside the distribution).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dim = 16                               # dimensions\nn_data = 100                           # number of data points\nstd = np.exp(-np.linspace(0, 4, dim))  # standard deviations\nuniform = 3                            # width of the uniform outlier distribution\n\ncolumns = [f\"dim {i + 1}\" for i in range(dim)]\ndata = pd.DataFrame(np.random.normal(size=(n_data, dim)) * std, columns=columns)\noutlier = pd.DataFrame(np.random.uniform(-uniform, uniform, size=(n_data, dim)), columns=columns)\ndata['type'] = 'data'\noutlier['type'] = 'outlier'\nprint(f\"{dim} dimensions\")\nprint(f\"{n_data} data points\")\nprint(f\"std: {std.round(2)}\")\nprint(f\"outliers in [-{uniform}, {uniform}]\")\nplt.plot(std, '-o');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can create scatter plots for all pairs of dimensions, which gives a rough idea of the two distributions\n(commented out because it takes very long).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# combined = pd.concat([outlier, data], ignore_index=True)\n# p = sns.pairplot(combined, hue='type', palette=['blue', 'red'], diag_kind=None)\n# for ax in p.axes.flatten():\n#     ax.set_xlim(-uniform, uniform)\n#     ax.set_ylim(-uniform, uniform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sonification\n\nLowest and highest frequency that may appear in the sonification, just for reference.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_freq = 110\namps = [1 if (i==0 or i==dim-1) else 0 for i in range(dim)]\nhs.audio(hs.render(hs.harmonic_tone(base_freq, amps=amps)))\namps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper functions to extract data points, randomise their order (for the experiment), and sonify them\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_points(data, outlier, shuffle):\n    points = []\n    for d, l in [(data, 'data'), (outlier, 'outlier')]:\n        if d is not None:\n            d = d[:,:-1]\n            points += [(d, f'{l} {i + 1}') for i, d in enumerate(d)]\n    if shuffle:\n        random.shuffle(points)\n    points, labels = list(zip(*points))\n    return np.array(points), labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def sonify(points, labels, std, base_freq, add_fundamental=True, label=False, print_amps=False):\n    points = np.abs(points)\n    points /= std[None, :]\n    points /= points.max()\n    for i, (p, l) in enumerate(zip(points, labels)):\n        if add_fundamental:\n            amps = [1] + list(p)\n        else:\n            amps = p\n        amps = np.array(amps, dtype=float)\n        if label:\n            print(l)\n        else:\n            print(f\"point {i + 1}\")\n        if print_amps:\n            print(amps.round(2))\n        hs.audio(hs.harmonic_tone(base_freq, amps=amps))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Data\n\nHere are some typical data points as well as some outliers.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_examples = 5\npoints, labels = get_points(data.values[:n_examples], outlier.values[:n_examples], False)\nsonify(points, labels, std, base_freq, label=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trials\n\nNow we get some data points and outliers shuffle them randomly and let participants guess.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_test = 10\npoints, labels = get_points(data=data.values[n_examples:n_examples+n_test], \n                            outlier=outlier.values[n_examples:n_examples+n_test], \n                            shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the evaluation, we once print their correct labels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for l in labels:\n    print(l)\nprint(\"--------------------\")\nsonify(points, labels, std, base_freq, label=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we just print a point index (this is shown to the participants)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sonify(points, labels, std, base_freq)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}