
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/Harmonic_Sonification.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_Harmonic_Sonification.py>`
        to download the full example code.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_Harmonic_Sonification.py:


Harmonic Sonification
=====================

.. GENERATED FROM PYTHON SOURCE LINES 6-9

.. code-block:: Python


    # # Harmonic Sonification








.. GENERATED FROM PYTHON SOURCE LINES 10-25

.. code-block:: Python



    import random
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    import pandas as pd
    import harmonicsonification as hs
    hs.seed_everything(42)


    # ## Data Set Creation

    # We want to test whether our harmonic sonification approach allows users to distinguish typical data points from outliers just based on the sound. For this, we first create an artificial data set with the characteristics typically obtained from applying PCA (i.e. dimensions with decreasing variance). We then create an _outlier_ data set with uniformly distributed points (some of these points will be like typical data points, but most will fall outside the distribution).








.. GENERATED FROM PYTHON SOURCE LINES 26-47

.. code-block:: Python



    dim = 16                               # dimensions
    n_data = 100                           # number of data points
    std = np.exp(-np.linspace(0, 4, dim))  # standard deviations
    uniform = 3                            # width of the uniform outlier distribution

    columns = [f"dim {i + 1}" for i in range(dim)]
    data = pd.DataFrame(np.random.normal(size=(n_data, dim)) * std, columns=columns)
    outlier = pd.DataFrame(np.random.uniform(-uniform, uniform, size=(n_data, dim)), columns=columns)
    data['type'] = 'data'
    outlier['type'] = 'outlier'
    print(f"{dim} dimensions")
    print(f"{n_data} data points")
    print(f"std: {std.round(2)}")
    print(f"outliers in [-{uniform}, {uniform}]")
    plt.plot(std, '-o');


    # We can create scatter plots for all pairs of dimensions, which gives a rough idea of the two distributions.




.. image-sg:: /auto_examples/images/sphx_glr_Harmonic_Sonification_001.png
   :alt: Harmonic Sonification
   :srcset: /auto_examples/images/sphx_glr_Harmonic_Sonification_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    16 dimensions
    100 data points
    std: [1.   0.77 0.59 0.45 0.34 0.26 0.2  0.15 0.12 0.09 0.07 0.05 0.04 0.03
     0.02 0.02]
    outliers in [-3, 3]

    [<matplotlib.lines.Line2D object at 0x7fb091832750>]



.. GENERATED FROM PYTHON SOURCE LINES 48-61

.. code-block:: Python



    # combined = pd.concat([outlier, data], ignore_index=True)
    # p = sns.pairplot(combined, hue='type', palette=['blue', 'red'], diag_kind=None)
    # for ax in p.axes.flatten():
    #     ax.set_xlim(-uniform, uniform)
    #     ax.set_ylim(-uniform, uniform)


    # ## Sonification

    # Lowest and highest frequency that may appear in the sonification, just for reference.








.. GENERATED FROM PYTHON SOURCE LINES 62-72

.. code-block:: Python



    base_freq = 110
    amps = [1 if (i==0 or i==dim-1) else 0 for i in range(dim)]
    hs.audio(hs.render(hs.harmonic_tone(base_freq, amps=amps)))
    amps


    # Helper functions to extract data points, randomise their order (for the experiment), and sonify them





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    <IPython.lib.display.Audio object>

    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]



.. GENERATED FROM PYTHON SOURCE LINES 73-87

.. code-block:: Python



    def get_points(data, outlier, shuffle):
        points = []
        for d, l in [(data, 'data'), (outlier, 'outlier')]:
            if d is not None:
                d = d[:,:-1]
                points += [(d, f'{l} {i + 1}') for i, d in enumerate(d)]
        if shuffle:
            random.shuffle(points)
        points, labels = list(zip(*points))
        return np.array(points), labels









.. GENERATED FROM PYTHON SOURCE LINES 88-113

.. code-block:: Python



    def sonify(points, labels, std, base_freq, add_fundamental=True, label=False, print_amps=False):
        points = np.abs(points)
        points /= std[None, :]
        points /= points.max()
        for i, (p, l) in enumerate(zip(points, labels)):
            if add_fundamental:
                amps = [1] + list(p)
            else:
                amps = p
            amps = np.array(amps, dtype=float)
            if label:
                print(l)
            else:
                print(f"point {i + 1}")
            if print_amps:
                print(amps.round(2))
            hs.audio(hs.harmonic_tone(base_freq, amps=amps))


    # ### Example Data

    # Here are some typical data points as well as some outliers.








.. GENERATED FROM PYTHON SOURCE LINES 114-120

.. code-block:: Python



    n_examples = 5
    points, labels = get_points(data.values[:n_examples], outlier.values[:n_examples], False)









.. GENERATED FROM PYTHON SOURCE LINES 121-130

.. code-block:: Python



    sonify(points, labels, std, base_freq, label=True)


    # ### Trials

    # Now we get some data points and outliers shuffle them randomly and let participants guess.





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    data 1
    <IPython.lib.display.Audio object>
    data 2
    <IPython.lib.display.Audio object>
    data 3
    <IPython.lib.display.Audio object>
    data 4
    <IPython.lib.display.Audio object>
    data 5
    <IPython.lib.display.Audio object>
    outlier 1
    <IPython.lib.display.Audio object>
    outlier 2
    <IPython.lib.display.Audio object>
    outlier 3
    <IPython.lib.display.Audio object>
    outlier 4
    <IPython.lib.display.Audio object>
    outlier 5
    <IPython.lib.display.Audio object>




.. GENERATED FROM PYTHON SOURCE LINES 131-141

.. code-block:: Python



    n_test = 10
    points, labels = get_points(data=data.values[n_examples:n_examples+n_test], 
                                outlier=outlier.values[n_examples:n_examples+n_test], 
                                shuffle=True)


    # For the evaluation, we once print their correct labels.








.. GENERATED FROM PYTHON SOURCE LINES 142-152

.. code-block:: Python



    for l in labels:
        print(l)
    print("--------------------")
    sonify(points, labels, std, base_freq, label=True)


    # Now we just print a point index (this is shown to the participants)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    outlier 10
    data 6
    outlier 5
    data 5
    data 10
    outlier 4
    outlier 6
    outlier 9
    data 7
    outlier 3
    outlier 8
    outlier 1
    data 2
    outlier 2
    data 3
    outlier 7
    data 8
    data 9
    data 1
    data 4
    --------------------
    outlier 10
    <IPython.lib.display.Audio object>
    data 6
    <IPython.lib.display.Audio object>
    outlier 5
    <IPython.lib.display.Audio object>
    data 5
    <IPython.lib.display.Audio object>
    data 10
    <IPython.lib.display.Audio object>
    outlier 4
    <IPython.lib.display.Audio object>
    outlier 6
    <IPython.lib.display.Audio object>
    outlier 9
    <IPython.lib.display.Audio object>
    data 7
    <IPython.lib.display.Audio object>
    outlier 3
    <IPython.lib.display.Audio object>
    outlier 8
    <IPython.lib.display.Audio object>
    outlier 1
    <IPython.lib.display.Audio object>
    data 2
    <IPython.lib.display.Audio object>
    outlier 2
    <IPython.lib.display.Audio object>
    data 3
    <IPython.lib.display.Audio object>
    outlier 7
    <IPython.lib.display.Audio object>
    data 8
    <IPython.lib.display.Audio object>
    data 9
    <IPython.lib.display.Audio object>
    data 1
    <IPython.lib.display.Audio object>
    data 4
    <IPython.lib.display.Audio object>




.. GENERATED FROM PYTHON SOURCE LINES 153-157

.. code-block:: Python



    sonify(points, labels, std, base_freq)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    point 1
    <IPython.lib.display.Audio object>
    point 2
    <IPython.lib.display.Audio object>
    point 3
    <IPython.lib.display.Audio object>
    point 4
    <IPython.lib.display.Audio object>
    point 5
    <IPython.lib.display.Audio object>
    point 6
    <IPython.lib.display.Audio object>
    point 7
    <IPython.lib.display.Audio object>
    point 8
    <IPython.lib.display.Audio object>
    point 9
    <IPython.lib.display.Audio object>
    point 10
    <IPython.lib.display.Audio object>
    point 11
    <IPython.lib.display.Audio object>
    point 12
    <IPython.lib.display.Audio object>
    point 13
    <IPython.lib.display.Audio object>
    point 14
    <IPython.lib.display.Audio object>
    point 15
    <IPython.lib.display.Audio object>
    point 16
    <IPython.lib.display.Audio object>
    point 17
    <IPython.lib.display.Audio object>
    point 18
    <IPython.lib.display.Audio object>
    point 19
    <IPython.lib.display.Audio object>
    point 20
    <IPython.lib.display.Audio object>





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 1.619 seconds)


.. _sphx_glr_download_auto_examples_Harmonic_Sonification.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: Harmonic_Sonification.ipynb <Harmonic_Sonification.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: Harmonic_Sonification.py <Harmonic_Sonification.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: Harmonic_Sonification.zip <Harmonic_Sonification.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
